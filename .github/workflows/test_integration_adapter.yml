name: Test dbt-fal encapsulate adapter

on:
  pull_request:
    types: [assigned, opened, synchronize, reopened]
    paths:
      - "adapter/**"
      - ".github/**"
      - "!.github/workflows/*cli*"

  push:
    branches: [main]
    paths:
      - "adapter/**"

  schedule:
    # every midnight
    - cron: "0 0 * * *"

  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        profile: ["postgres", "bigquery", "duckdb"]
        python: ["3.7", "3.8"]

    concurrency:
      group: "${{ github.head_ref || github.run_id }}-${{ github.workflow }}-${{ matrix.profile }}-${{ matrix.python }}"
      cancel-in-progress: true

    steps:
      - uses: actions/checkout@v2
        with:
          path: 'fal'

      - name: Start Docker database
        working-directory: fal/integration_tests
        if: contains(fromJSON('["postgres"]'), matrix.profile)
        run: docker-compose up -d

      - name: Setup latest dependencies
        working-directory: fal/adapter/integration_tests
        run: |
          python -m venv .venv
          source .venv/bin/activate
          pip install --upgrade pip==20.3
          pip install build wheel

          pip install dbt-${{ matrix.profile }}

          pushd ..
          pip install --use-deprecated=legacy-resolver ".[${{ matrix.profile }}]"
          popd

      - name: Setup behave
        working-directory: fal/adapter/integration_tests
        run: pip install behave

      - name: Run tests
        id: test_run
        working-directory: fal/adapter/integration_tests
        env:
          FAL_STATS_ENABLED: false
          # BigQuery
          KEYFILE: ${{ secrets.GCP_SA_KEY }}
          GCLOUD_PROJECT: ${{ secrets.GCP_PROJECT_ID }}
          BQ_DATASET: ${{ secrets.BQ_DATASET }}
          # Snowflake
          SF_ACCOUNT: ${{ secrets.SF_ACCOUNT }}
          SF_USER: ${{ secrets.SF_USER }}
          SF_PASSWORD: ${{ secrets.SF_PASSWORD }}
          SF_ROLE: ${{ secrets.SF_ROLE }}
          SF_DATABASE: ${{ secrets.SF_DATABASE }}
          SF_WAREHOUSE: ${{ secrets.SF_WAREHOUSE }}
          SF_SCHEMA: ${{ secrets.SF_SCHEMA }}
          # Duckdb
          DB_PATH: ${{ github.workspace }}/duck.db
        run: |
          source .venv/bin/activate

          # Database and schema setup for sources
          if [[ '${{ matrix.profile }}' == "bigquery" ]]
          then
            export DBT_DATABASE="$GCLOUD_PROJECT" DBT_SCHEMA="$BQ_DATASET"
          fi
          if [[ '${{ matrix.profile }}' == "snowflake" ]]
          then
            export DBT_DATABASE="$SF_DATABASE" DBT_SCHEMA="$SF_SCHEMA"
          fi
          if [[ '${{ matrix.profile }}' == "duckdb" ]]
          then
            # TODO: which to use for sources? Example:
            #   database: "{{ env_var('DBT_DATABASE', 'test') }}"
            #   schema: "{{ env_var('DBT_SCHEMA', 'dbt_fal') }}"
            export DBT_DATABASE="" DBT_SCHEMA=""
          fi

          if [[ '${{ matrix.profile }}' == "bigquery" ]]
          then
            # Save the credentials to a keyfile
            echo $KEYFILE > $HOME/keyfile.json
            ls -la $HOME/keyfile.json
            export KEYFILE_DIR=$HOME
            echo 'keyfile is ready'
          fi

          # TODO: setup teleport tests

          # Could not get the real job_id easily from context
          UUID=$(uuidgen | head -c8)
          export DB_NAMESPACE="${{ github.run_id }}_${UUID}"

          behave -fplain -D profile=${{ matrix.profile }}

      - name: Send custom JSON data to Slack workflow
        if: (failure() || cancelled()) && github.event_name == 'schedule'
        id: slack
        uses: slackapi/slack-github-action@v1.18.0
        with:
          # For posting a rich message using Block Kit
          payload: |
            {
              "text": "Integration tests failed for dbt-${{ matrix.profile }}@${{ matrix.dbt }} (Python ${{ matrix.python }})\nhttps://github.com/fal-ai/fal/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
