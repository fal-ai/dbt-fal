name: Run Integration Tests on Different Profiles

on:
  schedule:
    # every midnight
    - cron: "0 0 * * *"
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        profile: ["postgres", "bigquery", "snowflake", "redshift"]
        python: ["3.7", "3.8", "3.9", "3.10"]

    steps:
      - uses: actions/checkout@v2

      - name: Setup local fal
        uses: ./.github/actions/setup-local-fal
        with:
          python: ${{ matrix.python }}
          adapter: ${{ matrix.profile }}

      - name: Start Docker database
        working-directory: integration_tests
        if: matrix.profile == 'redshift' || matrix.profile == 'postgres'
        run: docker-compose up -d

      - name: Setup behave
        working-directory: integration_tests
        run: pip install behave

      # Avoid running against the same profile at the same time
      - name: Set up mutex on profiles
        uses: ben-z/gh-action-mutex@v1.0-alpha-5
        if: matrix.profile != 'postgres'
        with:
          branch: gh-mutex-profile-${{ matrix.profile }}

      - name: Run tests
        id: test_run
        working-directory: integration_tests
        env:
          FAL_STATS_ENABLED: false
          # BigQuery
          KEYFILE: ${{ secrets.GCP_SA_KEY }}
          GCLOUD_PROJECT: ${{ secrets.GCP_PROJECT_ID }}
          BQ_DATASET: ${{ secrets.BQ_DATASET }}
          # Redshift
          RS_DB_NAME: ${{ secrets.RS_DB_NAME }}
          # TODO: change to {{ secrets.RS_SCHEMA }} when testing with real Redshift
          RS_SCHEMA: dbt_fal
          RS_HOST: ${{ secrets.RS_HOST }}
          RS_PASSWORD: ${{ secrets.RS_PASSWORD }}
          RS_PORT: ${{ secrets.RS_PORT }}
          RS_USER: ${{ secrets.RS_USER }}
          # Snowflake
          SF_ACCOUNT: ${{ secrets.SF_ACCOUNT }}
          SF_USER: ${{ secrets.SF_USER }}
          SF_PASSWORD: ${{ secrets.SF_PASSWORD }}
          SF_ROLE: ${{ secrets.SF_ROLE }}
          SF_DATABASE: ${{ secrets.SF_DATABASE }}
          SF_WAREHOUSE: ${{ secrets.SF_WAREHOUSE }}
          SF_SCHEMA: ${{ secrets.SF_SCHEMA }}
        run: |
          # Database and schema setup for sources
          if [[ '${{ matrix.profile }}' == "bigquery" ]]
          then
            export DBT_DATABASE="$GCLOUD_PROJECT" DBT_SCHEMA="$BQ_DATASET"
          fi
          if [[ '${{ matrix.profile }}' == "redshift" ]]
          then
            export DBT_DATABASE="$RS_DB_NAME" DBT_SCHEMA="$RS_SCHEMA"
          fi
          if [[ '${{ matrix.profile }}' == "snowflake" ]]
          then
            export DBT_DATABASE="$SF_DATABASE" DBT_SCHEMA="$SF_SCHEMA"
          fi

          if [[ '${{ matrix.profile }}' == "bigquery" ]]
          then
            echo $KEYFILE > $HOME/keyfile.json
            ls -la $HOME/keyfile.json
            export KEYFILE_DIR=$HOME
            echo 'keyfile is ready'
          fi

          behave --tags=~broken_profile --tags=~TODO-${{ matrix.profile }} -D profile=${{ matrix.profile }}

      - name: Send custom JSON data to Slack workflow
        if: failure() && github.ref_name == 'main'
        id: slack
        uses: slackapi/slack-github-action@v1.18.0
        with:
          # For posting a rich message using Block Kit
          payload: |
            {
              "text": "Integration tests failed for ${{ matrix.profile }}, Python version ${{ matrix.python }}. https://github.com/fal-ai/fal/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
