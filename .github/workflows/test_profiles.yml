name: Integration Tests

on:
  pull_request:
    types: [assigned, opened, synchronize, reopened]
    paths-ignore:
      - "examples/**"
      - "docsite/**"
      - "README.md"
      - "LICENSE"
      - "docker/**"

  push:
    branches: [main]

  schedule:
    # every midnight
    - cron: "0 0 * * *"

  workflow_dispatch:
    inputs:
      adapter:
        description: dbt Adapter to test with
        required: false
        default: "<ALL>"
        type: choice
        options:
          - "<ALL>"
          - postgres
          - bigquery
          - snowflake
          - redshift
          - duckdb

jobs:
  matrix-adapter:
    runs-on: ubuntu-latest
    outputs:
      list: ${{ steps.matrix-step.outputs.list }}
    steps:
      - id: matrix-step
        shell: python
        run: |
          ADAPTERS = ['postgres', 'bigquery', 'snowflake', 'redshift', 'duckdb']
          OUTPUT = ADAPTERS

          if '${{ github.event_name }}' == 'pull_request':
            PR_TITLE = '${{ github.event.pull_request.title }}'.lower()
            PR_BRANCH = '${{ github.head_ref }}'.lower()

            # Only test adapters mentioned in the pull request title or branch.
            # We always test postgres as a sanity check.
            OUTPUT = [a for a in ADAPTERS if a in PR_TITLE or a in PR_BRANCH or a == 'postgres']

          elif '${{ github.event_name }}' == 'push':
            OUTPUT = ['postgres']

          elif '${{ github.event_name }}' == 'workflow_dispatch':
            ADAPTER_CHOICE = '${{ github.event.inputs.adapter }}'
            if ADAPTER_CHOICE != '<ALL>':
              OUTPUT = [ADAPTER_CHOICE]

          import json
          print("::set-output name=list::" + json.dumps(OUTPUT))

  matrix-python:
    runs-on: ubuntu-latest
    outputs:
      list: ${{ steps.matrix-step.outputs.list }}
    steps:
      - id: matrix-step
        shell: python
        run: |
          VERSIONS=["3.7", "3.8", "3.9", "3.10"]
          OUTPUT=["3.8"]

          if '${{ github.event_name }}' == 'pull_request':
            PR_TITLE = '${{ github.event.pull_request.title }}'.lower()
            PR_BRANCH = '${{ github.head_ref }}'.lower()

            # Test version mentioned in the pull request title or branch.
            OUTPUT = [v for v in VERSIONS if v in PR_TITLE or v in PR_BRANCH]

            if not OUTPUT:
              # If none were found in PR info
              OUTPUT=["3.8"]

          elif '${{ github.event_name }}' in ('schedule', 'push'):
            OUTPUT=VERSIONS

          import json
          print("::set-output name=list::" + json.dumps(OUTPUT))

  matrix-dbt:
    runs-on: ubuntu-latest
    outputs:
      list: ${{ steps.matrix-step.outputs.list }}
    steps:
      - id: matrix-step
        shell: python
        run: |
          OUTPUT=["1.0.*", "1.1.*"]

          if '${{ github.event_name }}' == 'workflow_dispatch':
            OUTPUT=["latest"]

          import json
          print("::set-output name=list::" + json.dumps(OUTPUT))

  run:
    needs:
      - matrix-adapter
      - matrix-python
      - matrix-dbt
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        profile: ${{ fromJSON(needs.matrix-adapter.outputs.list) }}
        dbt: ${{ fromJSON(needs.matrix-dbt.outputs.list) }}
        python: ${{ fromJSON(needs.matrix-python.outputs.list) }}

    # Run only the latest commit pushed to PR
    concurrency:
      group: "${{ github.head_ref || github.run_id }}-${{ github.workflow }}-${{ matrix.profile }}-${{ matrix.dbt }}-${{ matrix.python }}"
      cancel-in-progress: true

    steps:
      - uses: actions/checkout@v2

      - name: Setup local fal
        uses: ./.github/actions/setup-local-fal
        with:
          python: ${{ matrix.python }}
          dbt: ${{ matrix.dbt }}
          adapter: ${{ matrix.profile }}

      - name: Start Docker database
        working-directory: integration_tests
        # TODO: make redshift use a real connection
        if: contains(fromJSON('["redshift", "postgres"]'), matrix.profile)
        run: docker-compose up -d

      - name: Setup behave
        working-directory: integration_tests
        run: pip install behave

      # Avoid running against the same profile at the same time
      - name: Set up mutex on profiles
        uses: ben-z/gh-action-mutex@v1.0-alpha-5
        if: contains(fromJSON('["bigquery", "snowflake", "redshift"]'), matrix.profile)
        with:
          branch: gh-mutex-profile-${{ matrix.profile }}

      - name: Run tests
        id: test_run
        working-directory: integration_tests
        env:
          FAL_STATS_ENABLED: false
          # BigQuery
          KEYFILE: ${{ secrets.GCP_SA_KEY }}
          GCLOUD_PROJECT: ${{ secrets.GCP_PROJECT_ID }}
          BQ_DATASET: ${{ secrets.BQ_DATASET }}
          # Redshift
          RS_DB_NAME: ${{ secrets.RS_DB_NAME }}
          # TODO: change to {{ secrets.RS_SCHEMA }} when testing with real Redshift
          RS_SCHEMA: dbt_fal
          RS_HOST: ${{ secrets.RS_HOST }}
          RS_PASSWORD: ${{ secrets.RS_PASSWORD }}
          RS_PORT: ${{ secrets.RS_PORT }}
          RS_USER: ${{ secrets.RS_USER }}
          # Snowflake
          SF_ACCOUNT: ${{ secrets.SF_ACCOUNT }}
          SF_USER: ${{ secrets.SF_USER }}
          SF_PASSWORD: ${{ secrets.SF_PASSWORD }}
          SF_ROLE: ${{ secrets.SF_ROLE }}
          SF_DATABASE: ${{ secrets.SF_DATABASE }}
          SF_WAREHOUSE: ${{ secrets.SF_WAREHOUSE }}
          SF_SCHEMA: ${{ secrets.SF_SCHEMA }}
          # Duckdb
          DB_PATH: ${{ github.workspace }}/duck.db
        run: |
          # Database and schema setup for sources
          if [[ '${{ matrix.profile }}' == "bigquery" ]]
          then
            export DBT_DATABASE="$GCLOUD_PROJECT" DBT_SCHEMA="$BQ_DATASET"
          fi
          if [[ '${{ matrix.profile }}' == "redshift" ]]
          then
            export DBT_DATABASE="$RS_DB_NAME" DBT_SCHEMA="$RS_SCHEMA"
          fi
          if [[ '${{ matrix.profile }}' == "snowflake" ]]
          then
            export DBT_DATABASE="$SF_DATABASE" DBT_SCHEMA="$SF_SCHEMA"
          fi

          if [[ '${{ matrix.profile }}' == "bigquery" ]]
          then
            echo $KEYFILE > $HOME/keyfile.json
            ls -la $HOME/keyfile.json
            export KEYFILE_DIR=$HOME
            echo 'keyfile is ready'
          fi

          BEHAVE_ARGS="--tags=-TODO-${{ matrix.profile }}"

          if [[ '${{ matrix.profile }}' != 'postgres' ]]
          then
            # 'broken_profile' tests only works for postgres right now
            BEHAVE_ARGS="$BEHAVE_ARGS --tags=-broken_profile"
          fi

          behave $BEHAVE_ARGS -D profile=${{ matrix.profile }}

      - name: Send custom JSON data to Slack workflow
        if: (failure() || cancelled()) && github.event_name == 'schedule'
        id: slack
        uses: slackapi/slack-github-action@v1.18.0
        with:
          # For posting a rich message using Block Kit
          payload: |
            {
              "text": "Integration tests failed for dbt-${{ matrix.profile }}@${{ matrix.dbt }} (Python ${{ matrix.python }})\nhttps://github.com/fal-ai/fal/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
